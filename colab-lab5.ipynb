{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q kaggle\nfrom google.colab import files\nuploaded = files.upload()\n!mkdir -p ~/.kaggle\n!cp kaggle.json ~/.kaggle/\n!chmod 600 ~/.kaggle/kaggle.json\n\n# Завантаження свого датасету\n!kaggle datasets download -d kovalkostiantyn/lab5-data\n!unzip -q lab5-data.zip -d /content/\n\nimport os\nimport json\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers, callbacks\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\nimport matplotlib.pyplot as plt\nimport random\nimport matplotlib.image as mpimg\nimport seaborn as sns\nfrom collections import Counter\nfrom google.colab import files \n\n# --- Константи ---\nDATASET_DIR = \"/content/train\"      # Тренувальний датасет\nTEST_DIR = \"/content/test\"          # Тестовий датасет\nIMG_SIZE = (299, 299)               # Розмір зображень для Inception\nBATCH_SIZE = 16                     \nEPOCHS = 20                        \nLR = 1e-4                           \nMODEL_PATH = \"/content/best_inception_binary.h5\"  \nCLASS_INDICES_JSON = \"/content/class_indices.json\"\nMETADATA_JSON = \"/content/metadata.json\"\n\n# Створення генераторів даних\ndef create_generators(dataset_dir=DATASET_DIR):\n    train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        rotation_range=30,\n        width_shift_range=0.12,\n        height_shift_range=0.12,\n        shear_range=0.12,\n        zoom_range=0.12,\n        horizontal_flip=True,\n        fill_mode='nearest',\n        validation_split=0.2\n    )\n    \n    train_gen = train_datagen.flow_from_directory(\n        dataset_dir,\n        target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        class_mode='binary',\n        subset='training',\n        shuffle=True\n    )\n    \n    val_gen = train_datagen.flow_from_directory(\n        dataset_dir,\n        target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        class_mode='binary',\n        subset='validation',\n        shuffle=False\n    )\n    \n    # Збереження мапування класів\n    with open(CLASS_INDICES_JSON, \"w\", encoding=\"utf-8\") as f:\n        json.dump(train_gen.class_indices, f, ensure_ascii=False, indent=2)\n    \n    return train_gen, val_gen\n\n# Модуль Inception \ndef inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj, name=None):\n    # 1x1\n    branch1 = layers.Conv2D(filters_1x1, (1,1), padding='same', activation='relu')(x)\n    \n    # 1x1 -> 3x3\n    branch3 = layers.Conv2D(filters_3x3_reduce, (1,1), padding='same', activation='relu')(x)\n    branch3 = layers.Conv2D(filters_3x3, (3,3), padding='same', activation='relu')(branch3)\n    \n    # 1x1 -> 3x3 -> 3x3\n    branch5 = layers.Conv2D(filters_5x5_reduce, (1,1), padding='same', activation='relu')(x)\n    branch5 = layers.Conv2D(filters_5x5, (3,3), padding='same', activation='relu')(branch5)\n    branch5 = layers.Conv2D(filters_5x5, (3,3), padding='same', activation='relu')(branch5)\n    \n    # Pool -> 1x1\n    branch_pool = layers.MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n    branch_pool = layers.Conv2D(filters_pool_proj, (1,1), padding='same', activation='relu')(branch_pool)\n    \n    return layers.concatenate([branch1, branch3, branch5, branch_pool], axis=-1, name=name)\n\n# Побудова моделі\ndef build_inception_like(input_shape=(299,299,3), dropout_rate=0.4):\n    inp = layers.Input(shape=input_shape)\n    \n    x = layers.Conv2D(32, (3,3), strides=(2,2), padding='valid', activation='relu')(inp)\n    x = layers.Conv2D(32, (3,3), padding='valid', activation='relu')(x)\n    x = layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n    x = layers.MaxPooling2D((3,3), strides=(2,2), padding='valid')(x)\n    \n    x = layers.Conv2D(80, (1,1), activation='relu')(x)\n    x = layers.Conv2D(192, (3,3), padding='valid', activation='relu')(x)\n    x = layers.MaxPooling2D((3,3), strides=(2,2), padding='valid')(x)\n    \n    x = inception_module(x, 64, 48, 64, 64, 96, 32, name=\"incept_1\")\n    x = inception_module(x, 64, 48, 64, 64, 96, 64, name=\"incept_2\")\n    x = layers.MaxPooling2D((3,3), strides=(2,2), padding='valid')(x)\n    \n    x = inception_module(x, 128, 96, 128, 96, 128, 128, name=\"incept_3\")\n    x = inception_module(x, 160, 112, 160, 112, 160, 128, name=\"incept_4\")\n    \n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(dropout_rate)(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dropout(dropout_rate/2)(x)\n    out = layers.Dense(1, activation='sigmoid')(x)\n    \n    model = models.Model(inputs=inp, outputs=out, name=\"InceptionLike_binary\")\n    return model\n\n# Компіляція та навчання\ndef compile_and_train(model, train_gen, val_gen, epochs=EPOCHS):\n    model.compile(\n        optimizer=optimizers.Adam(learning_rate=LR),\n        loss='binary_crossentropy',\n        metrics=[\n            'accuracy',\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall')\n        ]\n    )\n    \n    # Балансування класів\n    counter = Counter(train_gen.classes)\n    majority = max(counter.values())\n    class_weight = {cls: float(majority / count) for cls, count in counter.items()}\n    \n    # Колбеки\n    cb = [\n        callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n        callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7, verbose=1),\n        callbacks.ModelCheckpoint(MODEL_PATH, save_best_only=True, monitor='val_loss', verbose=1)\n    ]\n    \n    history = model.fit(\n        train_gen,\n        validation_data=val_gen,\n        epochs=epochs,\n        class_weight=class_weight,\n        callbacks=cb,\n        verbose=1\n    )\n    \n    return history\n\n# Оцінка моделі\ndef evaluate_model(model, val_gen):\n    val_gen.reset()\n    preds = model.predict(val_gen, verbose=1).ravel()\n    y_pred = (preds > 0.5).astype(int)\n    y_true = val_gen.classes\n    \n    acc = accuracy_score(y_true, y_pred)\n    prec = precision_score(y_true, y_pred, zero_division=0)\n    rec = recall_score(y_true, y_pred, zero_division=0)\n    f1 = f1_score(y_true, y_pred, zero_division=0)\n    cm = confusion_matrix(y_true, y_pred)\n    \n    print(classification_report(y_true, y_pred, target_names=list(val_gen.class_indices.keys()), zero_division=0))\n    \n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=list(val_gen.class_indices.keys()),\n                yticklabels=list(val_gen.class_indices.keys()))\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n    \n    meta = {\"accuracy\": float(acc), \"precision\": float(prec), \"recall\": float(rec), \"f1\": float(f1)}\n    with open(METADATA_JSON, \"w\") as f:\n        json.dump(meta, f, indent=2)\n    \n    return {\"acc\":acc, \"prec\":prec, \"rec\":rec, \"f1\":f1, \"cm\":cm}\n\n# Графіки навчання\ndef plot_history(history):\n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n    \n    # Accuracy\n    if 'accuracy' in history.history and 'val_accuracy' in history.history:\n        axes[0, 0].plot(history.history['accuracy'], label='Train')\n        axes[0, 0].plot(history.history['val_accuracy'], label='Validation')\n        axes[0, 0].set_title('Accuracy')\n        axes[0, 0].legend()\n        axes[0, 0].grid(True)\n    else:\n        axes[0, 0].text(0.5, 0.5, 'Accuracy not found', ha='center', va='center')\n        axes[0, 0].set_title('Accuracy')\n\n    # Loss\n    if 'loss' in history.history and 'val_loss' in history.history:\n        axes[0, 1].plot(history.history['loss'], label='Train')\n        axes[0, 1].plot(history.history['val_loss'], label='Validation')\n        axes[0, 1].set_title('Loss')\n        axes[0, 1].legend()\n        axes[0, 1].grid(True)\n    else:\n        axes[0, 1].text(0.5, 0.5, 'Loss not found', ha='center', va='center')\n        axes[0, 1].set_title('Loss')\n\n    # Precision\n    if 'precision' in history.history and 'val_precision' in history.history:\n        axes[1, 0].plot(history.history['precision'], label='Train')\n        axes[1, 0].plot(history.history['val_precision'], label='Validation')\n        axes[1, 0].set_title('Precision')\n        axes[1, 0].legend()\n        axes[1, 0].grid(True)\n    else:\n        axes[1, 0].text(0.5, 0.5, 'Precision not found', ha='center', va='center')\n        axes[1, 0].set_title('Precision')\n\n    # Recall\n    if 'recall' in history.history and 'val_recall' in history.history:\n        axes[1, 1].plot(history.history['recall'], label='Train')\n        axes[1, 1].plot(history.history['val_recall'], label='Validation')\n        axes[1, 1].set_title('Recall')\n        axes[1, 1].legend()\n        axes[1, 1].grid(True)\n    else:\n        axes[1, 1].text(0.5, 0.5, 'Recall not found', ha='center', va='center')\n        axes[1, 1].set_title('Recall')\n\n    plt.tight_layout()\n    plt.show()\n\n# Прогноз на одному зображенні\ndef predict_image(model, image_path, class_indices_path=CLASS_INDICES_JSON):\n    img = tf.keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)\n    arr = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n    arr = np.expand_dims(arr, axis=0)\n    \n    prob = model.predict(arr, verbose=0)[0,0]\n    pred = int(prob > 0.5)\n    \n    with open(class_indices_path, \"r\", encoding=\"utf-8\") as f:\n        cls = json.load(f)\n    inv = {v: k for k, v in cls.items()}\n    label = inv.get(pred, str(pred))\n    \n    return label, float(prob)\n\n# Прогноз на випадкових зображеннях з датасету\ndef predict_random_from_dataset(model, dataset_dir=DATASET_DIR, num_samples=5):\n    if not os.path.exists(dataset_dir):\n        print(\"Папка з датасетом не знайдена!\")\n        return\n\n    # Завантажуємо мапування класів\n    with open(CLASS_INDICES_JSON, \"r\", encoding=\"utf-8\") as f:\n        class_indices = json.load(f)\n    index_to_class = {v: k for k, v in class_indices.items()}\n\n    # Збираємо всі файли зображень\n    image_paths = []\n    true_labels = []\n    for class_name in os.listdir(dataset_dir):\n        class_dir = os.path.join(dataset_dir, class_name)\n        if os.path.isdir(class_dir):\n            for fname in os.listdir(class_dir):\n                if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    image_paths.append(os.path.join(class_dir, fname))\n                    true_labels.append(class_name)\n\n    if len(image_paths) == 0:\n        print(\"Зображення не знайдено в датасеті!\")\n        return\n\n    # Випадковий вибір\n    indices = random.sample(range(len(image_paths)), min(num_samples, len(image_paths)))\n    \n    plt.figure(figsize=(15, 4 * ((len(indices) + 2) // 3)))\n    \n    for i, idx in enumerate(indices):\n        img_path = image_paths[idx]\n        true_label = true_labels[idx]\n\n        # Завантаження та прогноз\n        pred_label, prob = predict_image(model, img_path)\n        confidence = prob if pred_label == index_to_class[1] else (1 - prob)\n        is_correct = \"Правильно\" if pred_label == true_label else \"Помилка\"\n\n        # Відображення\n        plt.subplot((len(indices) + 2) // 3, 3, i + 1)\n        img = mpimg.imread(img_path)\n        plt.imshow(img)\n        plt.title(f\"Справжнє: {true_label}\\n\"\n                  f\"Прогноз: {pred_label} ({confidence:.1%})\\n\"\n                  f\"{is_correct}\", \n                  color='green' if is_correct == \"Правильно\" else 'red')\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\ndef main():\n    if not os.path.exists(DATASET_DIR):\n        print(\"Датасет не знайдено!\")\n        return\n    \n    print(\"Створення генераторів...\")\n    train_gen, val_gen = create_generators(DATASET_DIR)\n    \n    print(\"Побудова моделі...\")\n    model = build_inception_like()\n    model.summary()\n    \n    print(\"Навчання моделі...\")\n    history = compile_and_train(model, train_gen, val_gen, epochs=EPOCHS)\n    \n    print(\"Візуалізація результатів...\")\n    plot_history(history)\n    \n    print(\"Оцінка на валідації...\")\n    evaluate_model(model, val_gen)\n    \n    # --- Запуск перевірки на випадкових зображеннях ---\n    print(\"Перевірка на зображеннях з датасету(test)\")\n    best_model = tf.keras.models.load_model(MODEL_PATH)\n    predict_random_from_dataset(best_model, dataset_dir=DATASET_DIR, num_samples=6)\n\n# --- Запуск ---\nif __name__ == \"__main__\":\n    main()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Завантаження фото та прогноз\ndef upload_and_predict():\n    print(\"Завантажте зображення для класифікації:\")\n    uploaded = files.upload()\n    \n    if not uploaded:\n        print(\"Фото не завантажено.\")\n        return\n        \n    if not os.path.exists(MODEL_PATH):\n        print(\"Модель не знайдена! Спочатку навчіть модель.\")\n        return\n    \n    model = tf.keras.models.load_model(MODEL_PATH)\n    \n    for filename in uploaded.keys():\n        print(f\"\\nОбробка: {filename}\")\n        label, prob = predict_image(model, filename)\n        confidence = prob if label == list(model.output_names)[0] else (1 - prob)\n        print(f\"Прогноз: {label} (впевненість: {confidence:.2%})\")\nupload_and_predict()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}