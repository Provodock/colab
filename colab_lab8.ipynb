{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "colab_lab8",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q jiwer\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from jiwer import wer\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwUCUEVgqITK",
        "outputId": "01edca01-4334-4985-f943-57e82258366d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.19.0\n"
          ]
        }
      ],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "        print(f\"Використовується GPU: {gpus[0].name}\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    print(\"GPU не підключено! Рекомендується змінити Runtime на GPU.\")\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "EARLY_STOP_PATIENCE = 10\n",
        "MODEL_SAVE_PATH = \"deepspeech_model.keras\"\n",
        "\n",
        "FRAME_STEP = 256\n",
        "FFT_LENGTH = 256\n",
        "FRAME_LENGTH = 256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3N5JUuPqMuQ",
        "outputId": "89e1531a-ed4d-4151-e9e6-1ef11c0f1834"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Використовується GPU: /physical_device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Завантаження датасету LJSpeech\n",
        "ljspeech_ds = tfds.load(\"ljspeech\", split=\"train\", as_supervised=False)\n",
        "\n",
        "# Створення словника\n",
        "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
        "char_to_num = layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
        "num_to_char = layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True)\n",
        "\n",
        "print(f\"Словник створено. Розмір: {char_to_num.vocabulary_size()}\")\n",
        "\n",
        "# Функція для перетворення аудіо в спектрограму\n",
        "def encode_single_sample(sample):\n",
        "    audio = sample['speech']\n",
        "    label = sample['text']\n",
        "\n",
        "    # Обробка аудіо\n",
        "    audio = tf.cast(audio, tf.float32)\n",
        "    audio = tf.reshape(audio, [-1])\n",
        "\n",
        "    # Створення STFT спектрограми\n",
        "    spectrogram = tf.signal.stft(audio, frame_length=FRAME_LENGTH, frame_step=FRAME_STEP, fft_length=FFT_LENGTH)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
        "\n",
        "    # Нормалізація\n",
        "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
        "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
        "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
        "\n",
        "    # Обробка тексту\n",
        "    label = tf.strings.lower(label)\n",
        "    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
        "    label = char_to_num(label)\n",
        "\n",
        "    return spectrogram, label\n",
        "\n",
        "# Допоміжна функція для фільтрації та пакетування\n",
        "def get_spec_len(spec, label):\n",
        "    return tf.shape(spec)[0]\n",
        "\n",
        "# Створення pipeline для навчання\n",
        "train_dataset = (\n",
        "    ljspeech_ds\n",
        "    .map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .cache()\n",
        "    .shuffle(buffer_size=1000)\n",
        "    .bucket_by_sequence_length(\n",
        "        element_length_func=get_spec_len,\n",
        "        bucket_boundaries=[200, 300, 400, 500, 600, 700, 800],\n",
        "        bucket_batch_sizes=[BATCH_SIZE] * 8,\n",
        "        pad_to_bucket_boundary=False\n",
        "    )\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Розділення на train/val\n",
        "val_dataset = train_dataset.take(10)\n",
        "train_dataset = train_dataset.skip(10)\n",
        "\n",
        "print(\"Дані підготовлено та пайплайн налаштовано.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfilVQDSqPsU",
        "outputId": "e9616fbe-d64e-4315-8c78-83909d8f3d26"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Словник створено. Розмір: 31\n",
            "Дані підготовлено та пайплайн налаштовано.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функція втрат CTC (Connectionist Temporal Classification)\n",
        "def CTCLoss(y_true, y_pred):\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss\n",
        "\n",
        "def build_model(input_dim, output_dim, rnn_layers=2, rnn_units=128):\n",
        "    input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n",
        "\n",
        "    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n",
        "    x = layers.Conv2D(32, kernel_size=[11, 41], strides=[2, 2], padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(32, kernel_size=[11, 21], strides=[1, 2], padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    new_shape = (-1, x.shape[-2] * x.shape[-1])\n",
        "    x = layers.Reshape(target_shape=new_shape, name=\"reshape_rnn\")(x)\n",
        "    x = layers.Dense(rnn_units, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    for i in range(rnn_layers):\n",
        "        recurrent = layers.Bidirectional(\n",
        "            layers.LSTM(rnn_units, return_sequences=True), name=f\"bi_lstm_{i+1}\"\n",
        "        )(x)\n",
        "        x = layers.Dropout(0.2)(recurrent)\n",
        "\n",
        "    output = layers.Dense(output_dim + 1, activation=\"softmax\", name=\"output\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=input_spectrogram, outputs=output, name=\"DeepSpeech_Lite\")\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4), loss=CTCLoss)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Побудова моделі\n",
        "input_dim = FFT_LENGTH // 2 + 1\n",
        "model = build_model(input_dim=input_dim, output_dim=char_to_num.vocabulary_size(), rnn_units=256)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "4qrfNqUmqRuO",
        "outputId": "dfd856f7-88d0-4574-fae9-d5e315f0e80a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Архітектура моделі\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"DeepSpeech_Lite\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DeepSpeech_Lite\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ expand_dim (\u001b[38;5;33mReshape\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m14,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │       \u001b[38;5;34m236,576\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape_rnn (\u001b[38;5;33mReshape\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1056\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m270,592\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bi_lstm_1 (\u001b[38;5;33mBidirectional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bi_lstm_2 (\u001b[38;5;33mBidirectional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,574,912\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │        \u001b[38;5;34m16,416\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ expand_dim (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">236,576</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1056</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">270,592</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bi_lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bi_lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,416</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,163,840\u001b[0m (12.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,163,840</span> (12.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,163,712\u001b[0m (12.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,163,712</span> (12.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Навчання моделі\")\n",
        "\n",
        "early_stopper = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=EARLY_STOP_PATIENCE,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stopper],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"Модель збережено у {MODEL_SAVE_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Duwf9z7VqUMz",
        "outputId": "6e6b8e86-6981-4591-80ad-a1af2d68f035"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4. Навчання моделі\n",
            "Epoch 1/50\n",
            "    403/Unknown \u001b[1m500s\u001b[0m 1s/step - loss: 332.7082"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:160: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 1s/step - loss: 332.6522 - val_loss: 307.8203\n",
            "Epoch 2/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 691ms/step - loss: 296.8080 - val_loss: 348.7922\n",
            "Epoch 3/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 558ms/step - loss: 296.3033 - val_loss: 315.7209\n",
            "Epoch 4/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 561ms/step - loss: 292.5270 - val_loss: 306.3141\n",
            "Epoch 5/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 535ms/step - loss: 275.4167 - val_loss: 279.5395\n",
            "Epoch 6/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 569ms/step - loss: 245.9366 - val_loss: 232.5275\n",
            "Epoch 7/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 509ms/step - loss: 216.7764 - val_loss: 221.7677\n",
            "Epoch 8/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 485ms/step - loss: 202.4460 - val_loss: 191.9864\n",
            "Epoch 9/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 495ms/step - loss: 189.8213 - val_loss: 181.6561\n",
            "Epoch 10/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 510ms/step - loss: 178.2499 - val_loss: 163.3882\n",
            "Epoch 11/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 497ms/step - loss: 173.3419 - val_loss: 207.8941\n",
            "Epoch 12/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 499ms/step - loss: 169.0954 - val_loss: 146.1353\n",
            "Epoch 13/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 483ms/step - loss: 158.9045 - val_loss: 184.1857\n",
            "Epoch 14/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 496ms/step - loss: 154.8059 - val_loss: 166.7543\n",
            "Epoch 15/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 480ms/step - loss: 148.4508 - val_loss: 145.4446\n",
            "Epoch 16/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 504ms/step - loss: 145.9044 - val_loss: 146.0188\n",
            "Epoch 17/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 486ms/step - loss: 140.9105 - val_loss: 137.8118\n",
            "Epoch 18/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 577ms/step - loss: 136.3694 - val_loss: 148.7870\n",
            "Epoch 19/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 482ms/step - loss: 133.1992 - val_loss: 171.1255\n",
            "Epoch 20/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 482ms/step - loss: 130.8957 - val_loss: 133.3128\n",
            "Epoch 21/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 500ms/step - loss: 128.5316 - val_loss: 117.7445\n",
            "Epoch 22/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 479ms/step - loss: 126.6859 - val_loss: 118.6519\n",
            "Epoch 23/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 565ms/step - loss: 121.8475 - val_loss: 118.1981\n",
            "Epoch 24/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 484ms/step - loss: 119.0382 - val_loss: 149.9017\n",
            "Epoch 25/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 477ms/step - loss: 115.4836 - val_loss: 112.8830\n",
            "Epoch 26/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 496ms/step - loss: 113.9555 - val_loss: 147.6969\n",
            "Epoch 27/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 479ms/step - loss: 110.2542 - val_loss: 131.0320\n",
            "Epoch 28/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 492ms/step - loss: 109.8179 - val_loss: 155.5307\n",
            "Epoch 29/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 480ms/step - loss: 107.0760 - val_loss: 127.7568\n",
            "Epoch 30/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 480ms/step - loss: 106.3874 - val_loss: 116.6421\n",
            "Epoch 31/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 480ms/step - loss: 107.6635 - val_loss: 132.1174\n",
            "Epoch 32/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 480ms/step - loss: 106.8769 - val_loss: 117.5750\n",
            "Epoch 33/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 478ms/step - loss: 114.4125 - val_loss: 110.5396\n",
            "Epoch 34/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 496ms/step - loss: 109.0636 - val_loss: 120.1638\n",
            "Epoch 35/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 549ms/step - loss: 111.9504 - val_loss: 134.4540\n",
            "Epoch 36/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 485ms/step - loss: 122.9609 - val_loss: 146.7167\n",
            "Epoch 37/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 479ms/step - loss: 107.6671 - val_loss: 110.7605\n",
            "Epoch 38/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 481ms/step - loss: 107.6035 - val_loss: 130.1624\n",
            "Epoch 39/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 487ms/step - loss: 145.7365 - val_loss: 154.6630\n",
            "Epoch 40/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 479ms/step - loss: 127.3402 - val_loss: 141.4702\n",
            "Epoch 41/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 486ms/step - loss: 121.0313 - val_loss: 123.9688\n",
            "Epoch 42/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 486ms/step - loss: 110.9921 - val_loss: 144.1113\n",
            "Epoch 43/50\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 481ms/step - loss: 184.7955 - val_loss: 136.4590\n",
            "Epoch 43: early stopping\n",
            "Restoring model weights from the end of the best epoch: 33.\n",
            "Модель збережено у deepspeech_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Тестування моделі\")\n",
        "\n",
        "# Функція декодування\n",
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
        "\n",
        "    output_text = []\n",
        "    for result in results:\n",
        "        text = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(text)\n",
        "    return output_text\n",
        "\n",
        "TARGET_COUNT = 250\n",
        "collected_results = []\n",
        "processed_count = 0\n",
        "\n",
        "# Проходимо по валідаційному датасету\n",
        "for batch in val_dataset:\n",
        "    if processed_count >= TARGET_COUNT:\n",
        "        break\n",
        "\n",
        "    spectrograms = batch[0]\n",
        "    labels = batch[1]\n",
        "\n",
        "    # Передбачення для пакету\n",
        "    preds = model.predict(spectrograms, verbose=0)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "\n",
        "    # Обробка кожного елемента в пакеті\n",
        "    for i in range(len(pred_texts)):\n",
        "        if processed_count >= TARGET_COUNT:\n",
        "            break\n",
        "\n",
        "        true_label = tf.strings.reduce_join(num_to_char(labels[i])).numpy().decode(\"utf-8\")\n",
        "        pred_label = pred_texts[i]\n",
        "\n",
        "        # Обчислення помилки\n",
        "        error_rate = wer(true_label, pred_label)\n",
        "\n",
        "        # Зберігаємо результат: (WER, Справжній текст, Передбачений текст)\n",
        "        collected_results.append({\n",
        "            \"wer\": error_rate,\n",
        "            \"true\": true_label,\n",
        "            \"pred\": pred_label\n",
        "        })\n",
        "\n",
        "        processed_count += 1\n",
        "\n",
        "collected_results.sort(key=lambda x: x[\"wer\"])\n",
        "\n",
        "for i in range(10):\n",
        "    item = collected_results[i]\n",
        "    print(f\"WER: {item['wer']:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Справжній:   {item['true']}\")\n",
        "    print(f\"Передбачено: {item['pred']}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlePhE81qbpS",
        "outputId": "1a359075-b22f-4ef3-8520-3bef500bf2eb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тестування моделі\n",
            "WER: 0.1765\n",
            "----------------------------------------\n",
            "Справжній:   in concluding that oswald was carrying a rifle in the paper bag on the morning of november  \n",
            "Передбачено: in conclunding that oswald was carying a rifle in the paper bag on the morning of nevember \n",
            "\n",
            "\n",
            "WER: 0.2857\n",
            "----------------------------------------\n",
            "Справжній:   and kept altogether separate from the other prisoners until the day of his death\n",
            "Передбачено: and kept altogether seprtd from the othe prisoners until the da of his d\n",
            "\n",
            "\n",
            "WER: 0.2857\n",
            "----------------------------------------\n",
            "Справжній:   as it was occupied and appropriated in \n",
            "Передбачено: as it was ocupied and apropriated in \n",
            "\n",
            "\n",
            "WER: 0.2903\n",
            "----------------------------------------\n",
            "Справжній:   in his evidence before the inspectors he declared that for years he gave his whole time to his duties from an early hour in the morning till late in the afternoon\n",
            "Передбачено: in is evidence before the inspectors he declared that fr years he gave his hold time to his dutis from an arly our in the woring til late in the aftreno\n",
            "\n",
            "\n",
            "WER: 0.2917\n",
            "----------------------------------------\n",
            "Справжній:   it was also claimed for the more ample and more orderly distribution of victuals that the general health of the prisoners had greatly improved\n",
            "Передбачено: it was also claimed for the more ample and more orderly distrbution ovictuals that the geneal heltk of the prisoners ad greatly mproded\n",
            "\n",
            "\n",
            "WER: 0.3043\n",
            "----------------------------------------\n",
            "Справжній:   carro was the only one of oswald's three principal observers who recommended that he be placed in a boy's home or similar institution\n",
            "Передбачено: charo was the only one of oswald's tree principale observers who recomentded that he be placed in a boise home or sii oon\n",
            "\n",
            "\n",
            "WER: 0.3182\n",
            "----------------------------------------\n",
            "Справжній:   another statement which limits the time when it could have been written is the reference quote you and the baby end quote\n",
            "Передбачено: another statement which limits the time whan i could av been ritn is the reference quote u and the bay end quot\n",
            "\n",
            "\n",
            "WER: 0.3200\n",
            "----------------------------------------\n",
            "Справжній:   the other remaining unclaimed for ten years was transferred at the end of that time to the commissioners for the reduction of the national debt\n",
            "Передбачено: the other remaing untheclaimed for tan years was transferd at the endof that time to the commissioners for the reduction of the naton d\n",
            "\n",
            "\n",
            "WER: 0.3333\n",
            "----------------------------------------\n",
            "Справжній:   he whispered in the ear of the german pastor who attended him on the scaffold\n",
            "Передбачено: he was perding the ear of the jurman paster who attended him on the sal\n",
            "\n",
            "\n",
            "WER: 0.3333\n",
            "----------------------------------------\n",
            "Справжній:   daniel powers another marine who was stationed with oswald for part of his marine career\n",
            "Передбачено: danal powers another mariin who was station with oswald for part of his mar ar\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}